# Week Progress

**Date**: 2024-11-25 to 2024-11-29

## Overview
Several updates were made to the MLLM class by modifying the transformers library. The system does not work on the GPU if the CLIP model is running on the same device. After ensuring that the two models were synchronized the problem persisted. A solution was found by running the CLIP model on the CPU. However, this must slow down training so must be resolved.

After running several models with no warmup, schedular or LORA we found the initial results of the new MLLM class with TinyLLama improved on the performance of the baseline model created with the Vicuna-7b LLM:

### Accuracy:
<div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 10px;">
  <img src="Images/W&B%20Chart%2029_11_2024,%2011_42_03.png" alt="Image 1" style="flex: 1; max-width: 45%; height: auto;">
  <img src="Images/W&B%20Chart%2029_11_2024,%2011_42_08.png" alt="Image 2" style="flex: 1; max-width: 45%; height: auto;">
</div>

### Loss:
<div style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 10px;">
  <img src="Images/W&B%20Chart%2029_11_2024,%2011_41_44.png" alt="Image 1" style="flex: 1; max-width: 45%; height: auto;">
  <img src="Images/W&B%20Chart%2029_11_2024,%2011_41_58.png" alt="Image 2" style="flex: 1; max-width: 45%; height: auto;">
</div>

### Files modified:

[fine tuning script](https://github.com/sc20gb/MSc_Code/blob/main/fine_tune_with_gen.py)

[MLLM class](https://github.com/sc20gb/MSc_Code/blob/main/Model_Defs%2Fconnector_LLM_with_gen.py)

## Accomplishments

- Improved the performance of the model significantly, baseline validation performance was 24.12%
- Refined the new MLLM class
- Identified new ways to improve the efficiency of the model further

## Plans for Next Week

- Increase the speed of the model by:
    - Getting both models to run on the same device
    - Moving the generation of the loss to the outside of the new MLLM and LlamaForCausalLMCustom classes
- Compare the use of scheduling and warmup on the model's performance 
- Evaluate the best-performing model on test data
- Catchup on paper reading

