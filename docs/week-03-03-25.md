# Week Progress
**Date**: 2025-03-03 to 2025-03-07
## Overview
- The LLM draws out the domain specific information with the MLP projection. This helps it to leverage its understanding and achieve a better accuracy.
- However, this results in information the LLM could use is being disregarded.
- We remove this by applying a cosine similarity to reconstructed embeddings after the projection, adding the loss to the original.

## Other Ideas:
  - Due to the fact that the MLP clearly is benefitting the LLM in processing information.  We could try adding some larger more complex model as well as oar alongside the original embeddings:
    - the original would make the model generalisable and the extra processing of the embeddings would improve the MLLMs ability?

  - Could also try MoE on the embeddings?


  Questions?

  - Do Qformers have this same issue? And is the MLP acting as a bad Qformer, i.e selecting information that is helpful to the most likely query?
  - Can we improve this like the Qformers do but without using the query?


## Regularisation Results so Far

<img src="Images/reg_const2.PNG" alt="Image 1" style="flex: 1; max-width: 100%; height: auto;">

## Loss

- As the reg parameter increases the loss also increases. This means that the cosine similarity could not be being optimised as well, in which case the dimensionality reduction is resulting in most of the information loss.
- It should indicate that as the projection becomes better at reconstructing the original embeddings that the projection is no longer able to effectively preprocess the embeddings for the LLM. This is less likely as we see the accuracy increasing with the reg parameter, even if it is only slight.

## If the cosine loss is not able to decrease:

- It tells us that the LLM is not able to unprocess information that is compressed? Requiring extra help to make the embeddings better:
  - Could try taking the embeddings and spreading them across more embedding tokens, i.e increasing the available information the projections can provide. i.e one image embedding gets projected to two LLM embeddings?

## Accuracy

- A slight trend in the increase of the accuracy with a higher regularisation constant is shown.
- Once the constant is increased, hopefully we will see more consistent results.
- At the beginning of training g the loss is much higher,> 6.0. The reg loss by comparison can only be between 0.0 and 2.0. we may only see a better trend when we increase the constant further.
- One of the issues we are trying to solve is the LLM influences the projection very early, and causes loss of information it may benefit from later, i.e the projection is in a local minimum.


## Issues

- The cosine similarity does not take magnitude into account and only calculates the angles between the embeddings. Embeddings need to be normalised as to not affect the gradient.

## Plans for Next Week
- Record the two losses to see which causes more issues