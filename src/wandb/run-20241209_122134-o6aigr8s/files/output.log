Only one GPU available, models are split between GPU 0
loading pretrained CLIP visual encoder
0  warmup steps
770  total steps
1229.5  train batches
C:\Users\George\anaconda3\envs\CondaforDeepLearning\Lib\site-packages\transformers\models\llama\modeling_llama.py:602: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:455.)
  attn_output = torch.nn.functional.scaled_dot_product_attention(
tensor(52.5234, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.6662, device='cuda:0', grad_fn=<DivBackward0>)
tensor(24.3875, device='cuda:0', grad_fn=<DivBackward0>)
tensor(143.3540, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.5437, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.6732, device='cuda:0', grad_fn=<DivBackward0>)
tensor(62.1229, device='cuda:0', grad_fn=<DivBackward0>)
tensor(36.9658, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.4880, device='cuda:0', grad_fn=<DivBackward0>)
tensor(288.0412, device='cuda:0', grad_fn=<DivBackward0>)
tensor(63.5217, device='cuda:0', grad_fn=<DivBackward0>)
tensor(57.3542, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.1986, device='cuda:0', grad_fn=<DivBackward0>)
tensor(84.4843, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.1040, device='cuda:0', grad_fn=<DivBackward0>)
tensor(73.8566, device='cuda:0', grad_fn=<DivBackward0>)
tensor(70.3697, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.7509, device='cuda:0', grad_fn=<DivBackward0>)
tensor(160.2949, device='cuda:0', grad_fn=<DivBackward0>)
tensor(25.8295, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.7701, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.8570, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.0163, device='cuda:0', grad_fn=<DivBackward0>)
tensor(51.1062, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.5893, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.4455, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.3615, device='cuda:0', grad_fn=<DivBackward0>)
tensor(127.7547, device='cuda:0', grad_fn=<DivBackward0>)
tensor(83.6061, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.8337, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.5391, device='cuda:0', grad_fn=<DivBackward0>)
tensor(61.0555, device='cuda:0', grad_fn=<DivBackward0>)
tensor(68.6544, device='cuda:0', grad_fn=<DivBackward0>)
tensor(57.8757, device='cuda:0', grad_fn=<DivBackward0>)
tensor(111.9695, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.2071, device='cuda:0', grad_fn=<DivBackward0>)
tensor(69.6848, device='cuda:0', grad_fn=<DivBackward0>)
tensor(127.0135, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.8428, device='cuda:0', grad_fn=<DivBackward0>)
tensor(64.1428, device='cuda:0', grad_fn=<DivBackward0>)
tensor(27.6900, device='cuda:0', grad_fn=<DivBackward0>)
tensor(25.3476, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.8824, device='cuda:0', grad_fn=<DivBackward0>)
tensor(91.8181, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.7905, device='cuda:0', grad_fn=<DivBackward0>)
tensor(86.0145, device='cuda:0', grad_fn=<DivBackward0>)
tensor(67.3020, device='cuda:0', grad_fn=<DivBackward0>)
tensor(65.9677, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.1259, device='cuda:0', grad_fn=<DivBackward0>)
tensor(96.6895, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.2916, device='cuda:0', grad_fn=<DivBackward0>)
tensor(68.1407, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.1136, device='cuda:0', grad_fn=<DivBackward0>)
tensor(69.9043, device='cuda:0', grad_fn=<DivBackward0>)
tensor(78.1663, device='cuda:0', grad_fn=<DivBackward0>)
tensor(72.6017, device='cuda:0', grad_fn=<DivBackward0>)
tensor(58.0638, device='cuda:0', grad_fn=<DivBackward0>)
tensor(44.2890, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.6587, device='cuda:0', grad_fn=<DivBackward0>)
tensor(41.4334, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.4381, device='cuda:0', grad_fn=<DivBackward0>)
tensor(66.9254, device='cuda:0', grad_fn=<DivBackward0>)
tensor(43.6860, device='cuda:0', grad_fn=<DivBackward0>)
tensor(248.2497, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.9674, device='cuda:0', grad_fn=<DivBackward0>)
tensor(98.2836, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.6020, device='cuda:0', grad_fn=<DivBackward0>)
tensor(112.3620, device='cuda:0', grad_fn=<DivBackward0>)
tensor(123.5191, device='cuda:0', grad_fn=<DivBackward0>)
tensor(269.9597, device='cuda:0', grad_fn=<DivBackward0>)
tensor(210.9688, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.8069, device='cuda:0', grad_fn=<DivBackward0>)
tensor(107.0472, device='cuda:0', grad_fn=<DivBackward0>)
tensor(104.3791, device='cuda:0', grad_fn=<DivBackward0>)
tensor(288.6725, device='cuda:0', grad_fn=<DivBackward0>)
tensor(25.4365, device='cuda:0', grad_fn=<DivBackward0>)
All parameters are the same.
tensor(58.3621, device='cuda:0', grad_fn=<DivBackward0>)
tensor(58.0282, device='cuda:0', grad_fn=<DivBackward0>)
tensor(84.1325, device='cuda:0', grad_fn=<DivBackward0>)
tensor(90.2073, device='cuda:0', grad_fn=<DivBackward0>)
tensor(26.0158, device='cuda:0', grad_fn=<DivBackward0>)
tensor(67.9919, device='cuda:0', grad_fn=<DivBackward0>)
tensor(37.4374, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.2746, device='cuda:0', grad_fn=<DivBackward0>)
tensor(51.3905, device='cuda:0', grad_fn=<DivBackward0>)
tensor(85.6080, device='cuda:0', grad_fn=<DivBackward0>)
tensor(172.2200, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.7955, device='cuda:0', grad_fn=<DivBackward0>)
tensor(294.1042, device='cuda:0', grad_fn=<DivBackward0>)
tensor(129.6618, device='cuda:0', grad_fn=<DivBackward0>)
tensor(57.5414, device='cuda:0', grad_fn=<DivBackward0>)
tensor(212.2485, device='cuda:0', grad_fn=<DivBackward0>)
tensor(190.0347, device='cuda:0', grad_fn=<DivBackward0>)
tensor(28.0227, device='cuda:0', grad_fn=<DivBackward0>)
tensor(73.0523, device='cuda:0', grad_fn=<DivBackward0>)
tensor(66.3297, device='cuda:0', grad_fn=<DivBackward0>)
tensor(51.0509, device='cuda:0', grad_fn=<DivBackward0>)
tensor(26.8369, device='cuda:0', grad_fn=<DivBackward0>)
tensor(57.0969, device='cuda:0', grad_fn=<DivBackward0>)
tensor(78.3473, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.8173, device='cuda:0', grad_fn=<DivBackward0>)
tensor(239.7032, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.2292, device='cuda:0', grad_fn=<DivBackward0>)
tensor(318.7342, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.7274, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.4398, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.5058, device='cuda:0', grad_fn=<DivBackward0>)
tensor(154.7278, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.9808, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.5111, device='cuda:0', grad_fn=<DivBackward0>)
tensor(25.6452, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.1659, device='cuda:0', grad_fn=<DivBackward0>)
tensor(68.0939, device='cuda:0', grad_fn=<DivBackward0>)
tensor(301.5171, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.7109, device='cuda:0', grad_fn=<DivBackward0>)
tensor(65.2819, device='cuda:0', grad_fn=<DivBackward0>)
tensor(58.5745, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.1733, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.5157, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.7846, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.8923, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.5866, device='cuda:0', grad_fn=<DivBackward0>)
tensor(124.0558, device='cuda:0', grad_fn=<DivBackward0>)
tensor(154.1984, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.6155, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.9904, device='cuda:0', grad_fn=<DivBackward0>)
tensor(70.4202, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.2686, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.0587, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.8677, device='cuda:0', grad_fn=<DivBackward0>)
tensor(149.0906, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.5802, device='cuda:0', grad_fn=<DivBackward0>)
tensor(80.1396, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.3151, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.0623, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.3897, device='cuda:0', grad_fn=<DivBackward0>)
tensor(59.5372, device='cuda:0', grad_fn=<DivBackward0>)
tensor(57.1678, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.8692, device='cuda:0', grad_fn=<DivBackward0>)
tensor(41.1998, device='cuda:0', grad_fn=<DivBackward0>)
tensor(95.5959, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.7063, device='cuda:0', grad_fn=<DivBackward0>)
tensor(41.0260, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.3861, device='cuda:0', grad_fn=<DivBackward0>)
tensor(60.1027, device='cuda:0', grad_fn=<DivBackward0>)
tensor(257.6296, device='cuda:0', grad_fn=<DivBackward0>)
tensor(28.2719, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.9754, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.8523, device='cuda:0', grad_fn=<DivBackward0>)
tensor(59.1362, device='cuda:0', grad_fn=<DivBackward0>)
tensor(58.3298, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.3433, device='cuda:0', grad_fn=<DivBackward0>)
All parameters are the same.
tensor(270.3643, device='cuda:0', grad_fn=<DivBackward0>)
tensor(49.6281, device='cuda:0', grad_fn=<DivBackward0>)
tensor(99.0719, device='cuda:0', grad_fn=<DivBackward0>)
tensor(144.7819, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.8060, device='cuda:0', grad_fn=<DivBackward0>)
tensor(57.6515, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.6834, device='cuda:0', grad_fn=<DivBackward0>)
tensor(26.7128, device='cuda:0', grad_fn=<DivBackward0>)
tensor(25.4247, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.2541, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.0232, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.2403, device='cuda:0', grad_fn=<DivBackward0>)
tensor(41.3155, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.6782, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.4359, device='cuda:0', grad_fn=<DivBackward0>)
tensor(41.2263, device='cuda:0', grad_fn=<DivBackward0>)
tensor(102.7288, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.1494, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.1136, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.9783, device='cuda:0', grad_fn=<DivBackward0>)
tensor(244.7869, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.6239, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.0590, device='cuda:0', grad_fn=<DivBackward0>)
tensor(71.3920, device='cuda:0', grad_fn=<DivBackward0>)
tensor(43.9712, device='cuda:0', grad_fn=<DivBackward0>)
tensor(71.7335, device='cuda:0', grad_fn=<DivBackward0>)
tensor(58.5828, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.9303, device='cuda:0', grad_fn=<DivBackward0>)
tensor(25.7975, device='cuda:0', grad_fn=<DivBackward0>)
tensor(36.8335, device='cuda:0', grad_fn=<DivBackward0>)
tensor(51.2859, device='cuda:0', grad_fn=<DivBackward0>)
tensor(94.8858, device='cuda:0', grad_fn=<DivBackward0>)
tensor(59.0846, device='cuda:0', grad_fn=<DivBackward0>)
tensor(26.7105, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.3537, device='cuda:0', grad_fn=<DivBackward0>)
tensor(129.8311, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.1942, device='cuda:0', grad_fn=<DivBackward0>)
tensor(187.9055, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.7002, device='cuda:0', grad_fn=<DivBackward0>)
tensor(66.6511, device='cuda:0', grad_fn=<DivBackward0>)
tensor(69.7954, device='cuda:0', grad_fn=<DivBackward0>)
tensor(60.0429, device='cuda:0', grad_fn=<DivBackward0>)
tensor(155.1803, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.7429, device='cuda:0', grad_fn=<DivBackward0>)
tensor(50.5368, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.9442, device='cuda:0', grad_fn=<DivBackward0>)
tensor(223.0938, device='cuda:0', grad_fn=<DivBackward0>)
tensor(115.1565, device='cuda:0', grad_fn=<DivBackward0>)
tensor(57.6754, device='cuda:0', grad_fn=<DivBackward0>)
tensor(117.4147, device='cuda:0', grad_fn=<DivBackward0>)
tensor(109.9041, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.9993, device='cuda:0', grad_fn=<DivBackward0>)
tensor(39.7695, device='cuda:0', grad_fn=<DivBackward0>)
tensor(36.1066, device='cuda:0', grad_fn=<DivBackward0>)
tensor(142.2718, device='cuda:0', grad_fn=<DivBackward0>)
tensor(66.0422, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.8232, device='cuda:0', grad_fn=<DivBackward0>)
tensor(156.7199, device='cuda:0', grad_fn=<DivBackward0>)
tensor(238.8780, device='cuda:0', grad_fn=<DivBackward0>)
tensor(58.9116, device='cuda:0', grad_fn=<DivBackward0>)
tensor(148.0404, device='cuda:0', grad_fn=<DivBackward0>)
tensor(52.6364, device='cuda:0', grad_fn=<DivBackward0>)
tensor(55.7537, device='cuda:0', grad_fn=<DivBackward0>)
tensor(63.1815, device='cuda:0', grad_fn=<DivBackward0>)
tensor(90.1670, device='cuda:0', grad_fn=<DivBackward0>)
tensor(53.4028, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.4179, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.2554, device='cuda:0', grad_fn=<DivBackward0>)
tensor(54.4406, device='cuda:0', grad_fn=<DivBackward0>)
tensor(271.0746, device='cuda:0', grad_fn=<DivBackward0>)
tensor(27.1529, device='cuda:0', grad_fn=<DivBackward0>)
tensor(29.4072, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.1614, device='cuda:0', grad_fn=<DivBackward0>)
tensor(38.6232, device='cuda:0', grad_fn=<DivBackward0>)
tensor(68.4978, device='cuda:0', grad_fn=<DivBackward0>)
tensor(43.3113, device='cuda:0', grad_fn=<DivBackward0>)
All parameters are the same.
tensor(43.2851, device='cuda:0', grad_fn=<DivBackward0>)
tensor(51.1626, device='cuda:0', grad_fn=<DivBackward0>)
tensor(40.6803, device='cuda:0', grad_fn=<DivBackward0>)
tensor(51.7637, device='cuda:0', grad_fn=<DivBackward0>)
tensor(107.2360, device='cuda:0', grad_fn=<DivBackward0>)
tensor(86.8665, device='cuda:0', grad_fn=<DivBackward0>)
tensor(56.8984, device='cuda:0', grad_fn=<DivBackward0>)
tensor(67.1310, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.7550, device='cuda:0', grad_fn=<DivBackward0>)
tensor(42.0922, device='cuda:0', grad_fn=<DivBackward0>)
tensor(25.5223, device='cuda:0', grad_fn=<DivBackward0>)
Traceback (most recent call last):
  File "c:\Users\George\Desktop\Repositories\MSc_Code\fine_tune_with_gen.py", line 505, in <module>
    feature_aliginment_training(**para)
  File "c:\Users\George\Desktop\Repositories\MSc_Code\fine_tune_with_gen.py", line 312, in feature_aliginment_training
    loss.backward()
  File "C:\Users\George\anaconda3\envs\CondaforDeepLearning\Lib\site-packages\torch\_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "C:\Users\George\anaconda3\envs\CondaforDeepLearning\Lib\site-packages\torch\autograd\__init__.py", line 267, in backward
    _engine_run_backward(
  File "C:\Users\George\anaconda3\envs\CondaforDeepLearning\Lib\site-packages\torch\autograd\graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt