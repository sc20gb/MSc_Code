wandb_version: 1

vicuna_path:
  desc: null
  value: C:\Users\George\Desktop\Repositories\MSc_Code\Models\TinyLLama-v1.0
connector_layers:
  desc: null
  value: 2
embed_dim:
  desc: null
  value: 768
image_resolution:
  desc: null
  value: 224
lr:
  desc: null
  value: 0.0001
eps:
  desc: null
  value: 1.0e-08
weight_decay:
  desc: null
  value: 0.0001
per_warm:
  desc: null
  value: 0.33333
batch_size:
  desc: null
  value: 4
vir_batch_size:
  desc: null
  value: 64
rand_seed:
  desc: null
  value: 42
MAX_EPOC:
  desc: null
  value: 3
VERSION:
  desc: null
  value: 3005
save:
  desc: null
  value: false
cpu_only:
  desc: null
  value: false
hidden_layer_from_end:
  desc: null
  value: 1
training_step:
  desc: null
  value: 1
lora_dropout:
  desc: null
  value: 0.3
lora_rank:
  desc: null
  value: 8
pre_trained_connector_path:
  desc: null
  value: null
lora_alpha:
  desc: null
  value: 32
visual_encoder_type:
  desc: null
  value: CLIP-pretrained
use_half:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    python_version: 3.11.8
    cli_version: 0.17.7
    framework: huggingface
    huggingface_version: 4.46.2
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1733850854
    t:
      1:
      - 1
      - 2
      - 3
      - 5
      - 11
      - 41
      - 49
      - 53
      - 55
      - 71
      - 98
      - 105
      2:
      - 1
      - 2
      - 3
      - 5
      - 11
      - 41
      - 49
      - 53
      - 55
      - 71
      - 98
      - 105
      3:
      - 2
      - 16
      - 23
      4: 3.11.8
      5: 0.17.7
      6: 4.46.2
      8:
      - 3
      - 5
      13: windows-amd64
